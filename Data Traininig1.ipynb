{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50475e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "18/18 [==============================] - 1s 2ms/step - loss: 1.6949 - acc: 0.4815\n",
      "Epoch 2/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2574 - acc: 0.6861\n",
      "Epoch 3/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9581 - acc: 0.8025\n",
      "Epoch 4/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7398 - acc: 0.8836\n",
      "Epoch 5/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6087 - acc: 0.8977\n",
      "Epoch 6/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5105 - acc: 0.9171\n",
      "Epoch 7/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - acc: 0.9277\n",
      "Epoch 8/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3940 - acc: 0.9153\n",
      "Epoch 9/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3567 - acc: 0.9259\n",
      "Epoch 10/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3140 - acc: 0.9312\n",
      "Epoch 11/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2873 - acc: 0.9277\n",
      "Epoch 12/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2651 - acc: 0.9330\n",
      "Epoch 13/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2337 - acc: 0.9330\n",
      "Epoch 14/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2178 - acc: 0.9400\n",
      "Epoch 15/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1924 - acc: 0.9418\n",
      "Epoch 16/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1849 - acc: 0.9506\n",
      "Epoch 17/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1668 - acc: 0.9489\n",
      "Epoch 18/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1598 - acc: 0.9506\n",
      "Epoch 19/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1459 - acc: 0.9489\n",
      "Epoch 20/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1379 - acc: 0.9541\n",
      "Epoch 21/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1327 - acc: 0.9594\n",
      "Epoch 22/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1246 - acc: 0.9612\n",
      "Epoch 23/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1207 - acc: 0.9594\n",
      "Epoch 24/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1094 - acc: 0.9630\n",
      "Epoch 25/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1070 - acc: 0.9612\n",
      "Epoch 26/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1032 - acc: 0.9612\n",
      "Epoch 27/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0930 - acc: 0.9683\n",
      "Epoch 28/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0928 - acc: 0.9700\n",
      "Epoch 29/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0891 - acc: 0.9665\n",
      "Epoch 30/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0822 - acc: 0.9700\n",
      "Epoch 31/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0789 - acc: 0.9788\n",
      "Epoch 32/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0769 - acc: 0.9718\n",
      "Epoch 33/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0775 - acc: 0.9683\n",
      "Epoch 34/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0756 - acc: 0.9735\n",
      "Epoch 35/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0704 - acc: 0.9753\n",
      "Epoch 36/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0625 - acc: 0.9788\n",
      "Epoch 37/80\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0693 - acc: 0.9718\n",
      "Epoch 38/80\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0686 - acc: 0.9788\n",
      "Epoch 39/80\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0591 - acc: 0.9824\n",
      "Epoch 40/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0622 - acc: 0.9771\n",
      "Epoch 41/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0570 - acc: 0.9806\n",
      "Epoch 42/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0448 - acc: 0.9894\n",
      "Epoch 43/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0574 - acc: 0.9806\n",
      "Epoch 44/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0441 - acc: 0.9877\n",
      "Epoch 45/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0408 - acc: 0.9912\n",
      "Epoch 46/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0456 - acc: 0.9824\n",
      "Epoch 47/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0489 - acc: 0.9824\n",
      "Epoch 48/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0425 - acc: 0.9894\n",
      "Epoch 49/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0425 - acc: 0.9841\n",
      "Epoch 50/80\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0325 - acc: 0.9912\n",
      "Epoch 51/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0449 - acc: 0.9859\n",
      "Epoch 52/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0272 - acc: 0.9912\n",
      "Epoch 53/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0345 - acc: 0.9877\n",
      "Epoch 54/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0397 - acc: 0.9877\n",
      "Epoch 55/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0267 - acc: 0.9912\n",
      "Epoch 56/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0330 - acc: 0.9894\n",
      "Epoch 57/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0240 - acc: 0.9947\n",
      "Epoch 58/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0285 - acc: 0.9929\n",
      "Epoch 59/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0287 - acc: 0.9894\n",
      "Epoch 60/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0207 - acc: 0.9947\n",
      "Epoch 61/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0281 - acc: 0.9894\n",
      "Epoch 62/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0264 - acc: 0.9894\n",
      "Epoch 63/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0169 - acc: 0.9965\n",
      "Epoch 64/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0238 - acc: 0.9947\n",
      "Epoch 65/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0214 - acc: 0.9929\n",
      "Epoch 66/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0207 - acc: 0.9947\n",
      "Epoch 67/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0206 - acc: 0.9947\n",
      "Epoch 68/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0166 - acc: 0.9965\n",
      "Epoch 69/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0215 - acc: 0.9929\n",
      "Epoch 70/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0187 - acc: 0.9929\n",
      "Epoch 71/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0229 - acc: 0.9947\n",
      "Epoch 72/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0166 - acc: 0.9947\n",
      "Epoch 73/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0238 - acc: 0.9929\n",
      "Epoch 74/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0138 - acc: 0.9947\n",
      "Epoch 75/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0127 - acc: 0.9982\n",
      "Epoch 76/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0187 - acc: 0.9929\n",
      "Epoch 77/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0158 - acc: 0.9965\n",
      "Epoch 78/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0132 - acc: 0.9947\n",
      "Epoch 79/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0122 - acc: 0.9982\n",
      "Epoch 80/80\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0190 - acc: 0.9894\n"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "import numpy as np \n",
    "import cv2 \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.layers import Input, Dense \n",
    "from keras.models import Model\n",
    " \n",
    "is_init = False\n",
    "size = -1\n",
    "\n",
    "label = []\n",
    "dictionary = {}\n",
    "c = 0\n",
    "\n",
    "for i in os.listdir():\n",
    "\tif i.split(\".\")[-1] == \"npy\" and not(i.split(\".\")[0] == \"labels\"):  \n",
    "\t\tif not(is_init):\n",
    "\t\t\tis_init = True \n",
    "\t\t\tX = np.load(i)\n",
    "\t\t\tsize = X.shape[0]\n",
    "\t\t\ty = np.array([i.split('.')[0]]*size).reshape(-1,1)\n",
    "\t\telse:\n",
    "\t\t\tX = np.concatenate((X, np.load(i)))\n",
    "\t\t\ty = np.concatenate((y, np.array([i.split('.')[0]]*size).reshape(-1,1)))\n",
    "\n",
    "\t\tlabel.append(i.split('.')[0])\n",
    "\t\tdictionary[i.split('.')[0]] = c  \n",
    "\t\tc = c+1\n",
    "\n",
    "\n",
    "for i in range(y.shape[0]):\n",
    "\ty[i, 0] = dictionary[y[i, 0]]\n",
    "y = np.array(y, dtype=\"int32\")\n",
    "\n",
    "\n",
    "y = to_categorical(y)\n",
    "\n",
    "X_new = X.copy()\n",
    "y_new = y.copy()\n",
    "counter = 0 \n",
    "\n",
    "cnt = np.arange(X.shape[0])\n",
    "np.random.shuffle(cnt)\n",
    "\n",
    "for i in cnt: \n",
    "\tX_new[counter] = X[i]\n",
    "\ty_new[counter] = y[i]\n",
    "\tcounter = counter + 1\n",
    "\n",
    "\n",
    "ip = Input(shape=(X.shape[1]))\n",
    "\n",
    "m = Dense(128, activation=\"tanh\")(ip)\n",
    "m = Dense(64, activation=\"tanh\")(m)\n",
    "\n",
    "op = Dense(y.shape[1], activation=\"softmax\")(m) \n",
    "\n",
    "model = Model(inputs=ip, outputs=op)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss=\"categorical_crossentropy\", metrics=['acc'])\n",
    "\n",
    "model.fit(X_new, y_new, epochs=80)\n",
    "\n",
    "\n",
    "model.save(\"model.h5\")\n",
    "np.save(\"labels.npy\", np.array(label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87f1aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
